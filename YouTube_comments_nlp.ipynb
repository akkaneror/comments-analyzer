{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "%matplotlib inline\nimport re\nimport matplotlib\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "pd.options.display.max_colwidth \u003d 100",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "df \u003d pd.read_csv(\u0027compounds.csv\u0027,header \u003d None)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "view_stats \u003d df.iloc[0,:]",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "print(\"so we have \" + str(view_stats[0]) +\" view counts, \"+str(view_stats[1])+\" likes, \"+str(view_stats[2])+\" dislikes. \")",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "We can also try to see how it looks like by creating a pie-chart",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "import plotly.plotly as py\nimport plotly.graph_objs as go\n\nlabels \u003d [\u0027Likecout\u0027,\u0027Dislikecount\u0027]\nvalues \u003d [view_stats[1],view_stats[2]]\n\ntrace \u003d go.Pie(labels\u003dlabels, values\u003dvalues)\n\npy.iplot([trace], filename\u003d\u0027basic_pie_chart\u0027)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "So the cahrt above can present **visualisation** of how likeable our video is.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "df \u003d df.drop(index \u003d 0)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "df \u003d df.rename(columns \u003d {0:\u0027text\u0027,1:\u0027score\u0027,2:\u0027likecount\u0027})",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "df \u003d df.reset_index(drop \u003d True)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "def Clean_Text(text):\n    \"\"\"\n    text: input for the text\n    Disclaimer:\n    This is a ongoing cleaning function\n    \"\"\"\n\n    text \u003d text.lower()\n    text \u003d re.sub(r\"what\u0027s\", \"what is \", text)\n    text \u003d re.sub(r\"\\\u0027s\", \" \", text)\n    text \u003d re.sub(r\"\\\u0027ve\", \" have \", text)\n    text \u003d re.sub(r\"can\u0027t\", \"can not \", text)\n    text \u003d re.sub(r\"n\u0027t\", \" not \", text)\n    text \u003d re.sub(r\"i\u0027m\", \"i am \", text)\n    text \u003d re.sub(r\"he\u0027s\",\"he is \",text)\n    text \u003d re.sub(r\"she\u0027s\",\"she is \",text)\n    text \u003d re.sub(r\"\\\u0027re\", \" are \", text)\n    text \u003d re.sub(r\"\\\u0027d\", \" would \", text)\n    text \u003d re.sub(r\"\\\u0027ll\", \" will \", text)\n    text \u003d re.sub(r\"\\\u0027scuse\", \" excuse \", text)\n    text \u003d re.sub(\u0027\\W\u0027, \u0027 \u0027, text)\n    text \u003d re.sub(\u0027\\s+\u0027, \u0027 \u0027, text)\n    text \u003d re.sub(r\u0027[^\\w\\s]\u0027,\u0027\u0027,text)\n    text \u003d text.strip(\u0027 \u0027)\n    return text\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "df[\u0027clean_text\u0027] \u003d df[\u0027text\u0027].map(lambda com:Clean_Text(com))",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "df.head(10)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "So now since we have `cleaned text`, we are going to try use NLTK again to see the new score.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "from nltk.sentiment.vader import SentimentIntensityAnalyzer as sid\nsid \u003d sid()\ndf[\u0027clean_text_score\u0027] \u003d df[\u0027clean_text\u0027].map(lambda com:sid.polarity_scores(com)[\u0027compound\u0027])",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "df.head(3)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "What comments is the most likeable one ? And what\u0027s the score it get from the `polarity_scores` function ? ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "df_like_ranking \u003d df.sort_values(\u0027likecount\u0027,ascending \u003d False)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "df_like_ranking.head(10)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "If you wanna know **all** the likecount in a decending order ,just remove the `#` in the next chuck and it will show you the result.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "#df_like_ranking",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Of course the `polaity_scores` function itself can have some issues on giving score to the online comments ,some of them contains\n**sarcasm and slang** , those together all cause the fucntion to pick up and give scores. So for this, it\u0027s really important to see the **intersection of the most likeable and the highest score**.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "df.info()",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "def pick_up_comments(data,score,threshold):\n    \"\"\"\n    This function take three inputs:\n    - data :dataframe\n    - score : score you wannt to examine,input requires to be in [-1,1]. For negative numbers it will run scores no greater than the input,for positve\n        numbers it will find scores no smaller than the input.\n    - likecount : postive interger input required.\n    \n    \"\"\"\n    \n    if score \u003e 0:\n        df \u003d  data.loc[(df_like_ranking[\"clean_text_score\"] \u003e\u003d score) \u0026 (df_like_ranking[\"likecount\"] \u003e\u003d threshold)].sort_values([\u0027likecount\u0027, \u0027score\u0027],ascending\u003d[False, False])\n        return df\n    elif score \u003c\u003d 0:\n        df \u003d  data.loc[(df_like_ranking[\"clean_text_score\"] \u003c\u003d score) \u0026 (df_like_ranking[\"likecount\"] \u003e\u003d threshold)].sort_values([\u0027likecount\u0027, \u0027score\u0027],ascending\u003d[False, True])\n        return df\n              ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "----",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Here is just a part we are going to use the function to see how the `clean_text_score` interact with likecount.\nYou can change the number for your own analysis.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "pick_up_comments(df_like_ranking,0.8,50)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "pick_up_comments(df_like_ranking,-0.5,50)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "pick_up_comments(df_like_ranking,-0.4,50)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "pick_up_comments(df_like_ranking,-0.6,20)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "We can play with the function if we want to see how the comments distribute. ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "For this special case, specific analysis and detailed explanation would be useful for this single one video, so I will leave here .",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "-----",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "One thing I am interested in is the distribution of likecount of certain videos , let\u0027s check .",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# Histogram of the score",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "from scipy.stats import kurtosis\ndoanes \u003d lambda data: int(1 + np.log(len(data)) + np.log(1 +  kurtosis(data) * (len(data)/6.)** 0.5))",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "df_like_ranking.clean_text_score.hist()",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# Histogram of the score",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "from scipy.stats import kurtosis\ndoanes \u003d lambda data: int(1 + np.log(len(data)) + np.log(1 +  kurtosis(data) * (len(data)/6.)** 0.5))",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "df_like_ranking.likecount.hist(bins \u003d doanes(df_like_ranking[\"likecount\"]))",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "maybe try to plot scatter points betweeen `likecounts` and `clean_text_score`.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "sns.jointplot(x\u003d\"clean_text_score\", y\u003d\"likecount\", data\u003ddf_like_ranking)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}